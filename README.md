# LM Studio AI Chocolatey Package

<div align="center">
  <a href="https://github.com/MKAbuMattar/lm-studio-chocolatey-package">
    <img src="https://img.shields.io/badge/github-%23181717.svg?style=for-the-badge&logo=github&logoColor=white" alt="GitHub"/>
  </a>
  <a href="https://github.com/MKAbuMattar/lm-studio-chocolatey-package/stargazers">
    <img src="https://img.shields.io/github/stars/MKAbuMattar/lm-studio-chocolatey-package.svg?style=for-the-badge" alt="GitHub Stars"/>
  </a>
  <a href="https://github.com/MKAbuMattar/lm-studio-chocolatey-package/forks">
    <img src="https://img.shields.io/github/forks/MKAbuMattar/lm-studio-chocolatey-package.svg?style=for-the-badge" alt="GitHub Forks"/>
  </a>
  <a href="https://github.com/MKAbuMattar/lm-studio-chocolatey-package/issues">
    <img src="https://img.shields.io/github/issues/MKAbuMattar/lm-studio-chocolatey-package.svg?style=for-the-badge" alt="GitHub Issues"/>
  </a>
  <a href="LICENSE">
    <img src="https://img.shields.io/github/license/MKAbuMattar/lm-studio-chocolatey-package.svg?style=for-the-badge" alt="GitHub License"/>
  </a>
</div>

## Downloads

To install LM Studio, run the following command from the command line or from PowerShell:

```powershell
choco install lmstudio
```

This command will download the LM Studio installer from the official website and execute it silently.

## Manual Installation

To install LM Studio manually, download LM Studio from [lmstudio.ai](https://lmstudio.ai/).

## What is LM Studio?

This package automates the installation of the LM Studio application. LM Studio is a desktop application that allows you to run large language models (LLMs) on your laptop, entirely offline.

## Features

With LM Studio, you can:

â€¢ ðŸ¤– Run LLMs on your laptop, entirely offline

â€¢ ðŸ“š Chat with your local documents (new in 0.3)

â€¢ ðŸ‘¾ Use models through the in-app Chat UI or an OpenAI compatible local server

â€¢ ðŸ“‚ Download any compatible model files from Hugging Face ðŸ¤— repositories

â€¢ ðŸ”­ Discover new & noteworthy LLMs right inside the app's Discover page

LM Studio supports any GGUF `Llama 3.2`, `Mistral`, `Phi`, `Gemma`, `DeepSeek`, `Qwen 2.5`, `StarCoder`, etc model on Hugging Face.

## Minimum Requirements

Minimum requirements: M1/M2/M3/M4 Mac, or a Windows / Linux PC with a processor that supports AVX2.

Made possible thanks to the [llama.cpp project](https://github.com/ggerganov/llama.cpp).

## Documentation

Consult the Technical Documentation at [https://lmstudio.ai/docs](https://lmstudio.ai/docs).

## Frequently Asked Questions

### **Does LM Studio collect any data?**

No. One of the main reasons for using a local LLM is privacy, and LM Studio is designed for that. Your data remains private and local to your machine.

See [Documentation > Offline Operation](https://lmstudio.ai/docs/offline) for more.

### **What are the minimum hardware / software requirements?**

Visit the [System Requirements](https://lmstudio.ai/docs/system-requirements) page for the most up to date information.

## Stay Updated

ðŸš€ New in 0.3.10: `reasoning_content` in API responses and Idle TTL! Read the [announcement](https://lmstudio.ai/blog/lmstudio-v0.3.10).
